{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import struct\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import random_split, DataLoader\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "__all__ = [\"ColorMNIST\"]\n",
    "\n",
    "\n",
    "class ColorMNIST(Dataset):\n",
    "    def __init__(self, color, split, path, transform_list=[], randomcolor=False):\n",
    "        assert color in ['num', 'back', 'both'], \"color must be either 'num', 'back' or 'both\"\n",
    "        self.pallette = [[255, 0, 0],\n",
    "                         [255, 0, 0],\n",
    "                         [255, 0, 0],\n",
    "                         [0, 255, 0],\n",
    "                         [0, 255, 0],\n",
    "                         [0, 255, 0],\n",
    "                         [0, 0, 255],\n",
    "                         [0, 0, 255],\n",
    "                         [220, 220, 80],\n",
    "                         [220, 220, 80]]\n",
    "\n",
    "        if split == 'train':\n",
    "            fimages = os.path.join(path, 'raw', 'train-images-idx3-ubyte')\n",
    "            flabels = os.path.join(path, 'raw', 'train-labels-idx1-ubyte')\n",
    "        else:\n",
    "            fimages = os.path.join(path, 'raw', 't10k-images-idx3-ubyte')\n",
    "            flabels = os.path.join(path, 'raw', 't10k-labels-idx1-ubyte')\n",
    "\n",
    "        # Load images\n",
    "        with open(fimages, 'rb') as f:\n",
    "            _, _, rows, cols = struct.unpack(\">IIII\", f.read(16))\n",
    "            self.images = np.fromfile(f, dtype=np.uint8).reshape(-1, rows, cols)\n",
    "\n",
    "        # Load labels\n",
    "        with open(flabels, 'rb') as f:\n",
    "            struct.unpack(\">II\", f.read(8))\n",
    "            self.labels = np.fromfile(f, dtype=np.int8)\n",
    "            self.labels = torch.from_numpy(self.labels.astype(np.int))\n",
    "\n",
    "        self.transform_list = transform_list\n",
    "        self.color = color\n",
    "        self.images = np.tile(self.images[:, :, :, np.newaxis], 3)\n",
    "        self.randomcolor = randomcolor\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.images[idx]  # Range [0,255]\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        # Choose color\n",
    "        if self.randomcolor:\n",
    "            c = self.pallette[np.random.randint(0, 10)]\n",
    "            if self.color == 'both':\n",
    "                while True:\n",
    "                    c2 = self.pallette[np.random.randint(0, 10)]\n",
    "                    if c2 != c: break\n",
    "        else:\n",
    "            if self.color == 'num':\n",
    "                c = self.pallette[-(label + 1)]\n",
    "            elif self.color == 'back':\n",
    "                c = self.pallette[label]\n",
    "            else:\n",
    "                c = self.pallette[label]\n",
    "                c2 = self.pallette[-(label - 3)]\n",
    "\n",
    "        # Assign color according to their class (0,10)\n",
    "        if self.color == 'num':\n",
    "            image[:, :, 0] = image[:, :, 0] / 255 * c[0]\n",
    "            image[:, :, 1] = image[:, :, 1] / 255 * c[1]\n",
    "            image[:, :, 2] = image[:, :, 2] / 255 * c[2]\n",
    "        elif self.color == 'back':\n",
    "            image[:, :, 0] = (255 - image[:, :, 0]) / 255 * c[0]\n",
    "            image[:, :, 1] = (255 - image[:, :, 1]) / 255 * c[1]\n",
    "            image[:, :, 2] = (255 - image[:, :, 2]) / 255 * c[2]\n",
    "        else:\n",
    "            image[:, :, 0] = image[:, :, 0] / 255 * c[0] + (255 - image[:, :, 0]) / 255 * c2[0]\n",
    "            image[:, :, 1] = image[:, :, 1] / 255 * c[1] + (255 - image[:, :, 1]) / 255 * c2[1]\n",
    "            image[:, :, 2] = image[:, :, 2] / 255 * c[2] + (255 - image[:, :, 2]) / 255 * c2[2]\n",
    "\n",
    "        image = Image.fromarray(image)\n",
    "        for t in self.transform_list:\n",
    "            image = t(image)\n",
    "        image = transforms.ToTensor()(image)  # Range [0,1]\n",
    "\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_mnist = 'data/mnist'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define the NN architecture\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.l1 = nn.Linear(28*28, 256)\n",
    "        # linear layer (n_hidden -> hidden_2)\n",
    "        self.l2 = nn.Linear(256,256)\n",
    "        # linear layer (n_hidden -> 10)\n",
    "        self.l3 = nn.Linear(256,10)\n",
    "        # dropout prevents overfitting of data\n",
    "        self.dropout_l = nn.Dropout(0.1)\n",
    "\n",
    "    def forward(self,x):\n",
    "        # hidden layer 1\n",
    "        h1 = nn.functional.relu(self.l1(x))\n",
    "        # hidden layer 2\n",
    "        h2 =  nn.functional.relu(self.l2(h1))\n",
    "        # dropout layer\n",
    "        dropout_l = self.dropout_l(h2+h1)\n",
    "        # result layer\n",
    "        res = self.l3(dropout_l)\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to data\\MNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54e9f9c60b6645ac832cbde068254de1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9912422 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data\\MNIST\\raw\\train-images-idx3-ubyte.gz to data\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to data\\MNIST\\raw\\train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b838734b6024ea685171ebc17c8726d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/28881 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data\\MNIST\\raw\\train-labels-idx1-ubyte.gz to data\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to data\\MNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1a71272d3704588855fa7c00fe2bb35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1648877 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data\\MNIST\\raw\\t10k-images-idx3-ubyte.gz to data\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to data\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7df5422918149378c2e6534c15d23c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4542 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz to data\\MNIST\\raw\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# defining model with resnet\n",
    "model = Net()\n",
    "\n",
    "# defining epoch number and loss, accuracy list for plotting comparision graph\n",
    "n_epochs=5\n",
    "train_loss = []\n",
    "train_ac = []\n",
    "test_loss = []\n",
    "test_ac = []\n",
    "\n",
    "# specify optimizer\n",
    "params = model.parameters()\n",
    "optimiser=optim.SGD(params, lr=0.01)\n",
    "\n",
    "# specify loss function\n",
    "criterion=nn.CrossEntropyLoss() \n",
    "\n",
    "# choose and loading training and test datasets\n",
    "mnist_data=datasets.MNIST('data', train=True, download=True, transform=transforms.ToTensor())\n",
    "train_data, test_data= random_split(mnist_data, [55000,5000])\n",
    "train_loader = DataLoader(train_data, batch_size=32)\n",
    "test_loader= DataLoader(test_data, batch_size=32)\n",
    "\n",
    "torch.set_printoptions(precision=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\emren\\AppData\\Local\\Temp/ipykernel_16156/1559879144.py:34: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  self.labels = torch.from_numpy(self.labels.astype(np.int))\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataloader = ColorMNIST('num', 'train', path_to_mnist, randomcolor=False)\n",
    "dataloader2 = DataLoader(dataloader, batch_size=32)\n",
    "testloader = ColorMNIST('num', 'test', path_to_mnist, randomcolor=False)\n",
    "testloader2 = DataLoader(testloader, batch_size=32)\n",
    "\n",
    "x_all = []\n",
    "for i in [1, 3, 5, 7, 2, 0, 13, 15, 17, 4]:\n",
    "    x_all.append(dataloader[i][0].numpy().transpose([1, 2, 0]))\n",
    "x_all = np.hstack(x_all)\n",
    "\n",
    "plt.imshow(x_all)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected input batch_size (3) to match target batch_size (0).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_16156/1087092930.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[0moutput\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[1;31m# calculate the loss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m         \u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m         \u001b[1;31m# clear the gradients of all optimized variables\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\my_environment\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\my_environment\\lib\\site-packages\\torch\\nn\\modules\\loss.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input, target)\u001b[0m\n\u001b[0;32m   1148\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1149\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1150\u001b[1;33m         return F.cross_entropy(input, target, weight=self.weight,\n\u001b[0m\u001b[0;32m   1151\u001b[0m                                \u001b[0mignore_index\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mignore_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreduction\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1152\u001b[0m                                label_smoothing=self.label_smoothing)\n",
      "\u001b[1;32m~\\anaconda3\\envs\\my_environment\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mcross_entropy\u001b[1;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[0;32m   2844\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0msize_average\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mreduce\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2845\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2846\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcross_entropy_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel_smoothing\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2847\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2848\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Expected input batch_size (3) to match target batch_size (0)."
     ]
    }
   ],
   "source": [
    "for epoch in range(n_epochs):\n",
    "    # prep model for training\n",
    "    model.train()\n",
    "    # creating list to calculate loss and accuracy\n",
    "    loss_list=[]\n",
    "    ac_list=[]\n",
    "    \n",
    "    # train the model\n",
    "    for data,target in dataloader:\n",
    "        data_size=data.size(0)\n",
    "        data=data.view(data_size, -1)\n",
    "        # forward pass: compute predicted outputs by passing inputs to the model\n",
    "        output=model(data) \n",
    "        # calculate the loss\n",
    "        loss=criterion(output, target)\n",
    "        # clear the gradients of all optimized variables\n",
    "        model.zero_grad()\n",
    "        # backward pass: compute gradient of the loss with respect to model parameters\n",
    "        loss.backward()\n",
    "        # parameter update\n",
    "        optimiser.step()\n",
    "        # filling loss and accuracy list\n",
    "        loss_list.append(loss.item())\n",
    "        ac_list.append(target.eq(output.detach().argmax(dim=1).cpu()).float().mean())\n",
    "    # calculate loss and accuracy\n",
    "    train_loss.append(float(torch.tensor(loss_list).mean()) * 100)\n",
    "    train_ac.append(float(torch.tensor(ac_list).mean()) * 100)\n",
    "    print('Epoch: ', epoch+1, '   ','Training loss: ',torch.tensor(loss_list).mean(), '   ','Training accuracy: ',torch.tensor(ac_list).mean())\n",
    "    \n",
    "    # initialize lists to monitor test loss and accuracy\n",
    "    loss_list=[]\n",
    "    ac_list=[]\n",
    "    # *evaluation*\n",
    "    model.eval()\n",
    "\n",
    "    for data,target in testloader:\n",
    "        data_size=data.size(0)\n",
    "        data=data.view(data_size, -1)\n",
    "        # no grad\n",
    "        with torch.no_grad():\n",
    "            output=model(data)\n",
    "        # calculate the loss\n",
    "        loss=criterion(output, target) \n",
    "        # filling loss and accuracy list\n",
    "        loss_list.append(loss.item())\n",
    "        ac_list.append(target.eq(output.detach().argmax(dim=1).cpu()).float().mean())\n",
    "      \n",
    "  # calculate loss and accuracy   \n",
    "    test_loss.append(float(torch.tensor(loss_list).mean()) * 100)\n",
    "    test_ac.append(float(torch.tensor(ac_list).mean()) * 100)\n",
    "    print('Epoch: ', epoch+1, '   ','Training loss: ',torch.tensor(loss_list).mean(), '   ','Training accuracy: ',torch.tensor(ac_list).mean())\n",
    "    \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_axis = range(0,5)\n",
    "plt.plot(x_axis, train_loss, 'g', label='Training')\n",
    "plt.plot(x_axis, test_loss, data_size, label='Validation')\n",
    "plt.xlabel('Epoch number')\n",
    "plt.ylabel('Loss rate')\n",
    "plt.title('Graph of Losses')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x_axis, train_ac, 'g', label='Training')\n",
    "plt.plot(x_axis, test_ac, data_size, label='Validation')\n",
    "plt.xlabel('Epoch number')\n",
    "plt.ylabel('Accuracy rate')\n",
    "plt.title('Graph of Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
